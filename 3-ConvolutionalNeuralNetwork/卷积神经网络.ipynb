{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "diBZVtDsnd_M"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "path = os.getcwd()\n",
    "os.chdir('..')\n",
    "from deepnotes import *\n",
    "os.chdir(path)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# 使用Pytorch验算卷积和池化的梯度\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxCkbJmbLAR0"
   },
   "source": [
    "### 为什么使用卷积\n",
    "我们前一课学习了如何使用全连接网实现最简单的图像识别和分类, 尽管MNIST是非常容易训练的数据集, 但亲自开发一个可用的AI还是很激动人心的. 但是使用全连接网络虽然能解决很多传统机器学习方法面向的问题, 比如简单的模式分类和函数拟合. 但是设想一下, 我们实际要面对的可不是MNIST这种简单数据集, 而是特征更丰富, 分辨率更高的真实图像, 我们在网络上随便找一找就能找到大把的1000x800量级的图片. 如果我们把这种图片用来训练神经网络, 那么我们仅在第一层需要的参数就会达到1000x800xhidden size那么多, 这几乎是不可能接受的. 尽管我们也可以用预处理的方式降低分辨率, 但是这不免会丢失很多本应有的特征. 为此我们提出了二维卷积的方法帮助我们在图像中提取特征, 同时用池化方法实现图像压缩和数据降维.  \n",
    "![conv.gif](conv.gif)\n",
    "![edge_detection.jpg](edge_detection.jpg)\n",
    "上图是卷积运算的演算法, 以及某种卷积核作用于图像后的结果. 卷积运算可以提取图像的高级特征, 比如上面的卷积就能实现边缘检测的工作. 如果我们用级联的卷积核形成卷积层, 它还能得到某些更高级的特征. 比如我们可能在上面的这种特征图上再做卷积, 得到横线的边缘和竖线的边缘. 再卷积可能就能识别直角边缘的特征.  \n",
    "另外, 卷积并不是像上面那样只能操作一维图像, 通常我们的输入图像是RGB的三通道图像. 那么我们的卷积实际上是一个同为3维的卷积核按上图的方式滑动, 然后把这三个通道卷积运算得到的1维特征图相加. 如果我们用N个这样的3维卷积核把图片做N次卷积, 就能得到N通道的特征图. 那么下次卷积, 每个卷积核的维度就必须是N维, 如此类推.  \n",
    "卷积运算conv2d接收C维的特征图, 尺度为NxCxHxW. 卷积核的数量为FN, 通道数为C, 尺寸filter size自主给定, 步长stride一般为1. 输出特征图为$N*FN*\\frac{(H-size)+1}{stride}*\\frac{(W-size)+1}{stride}$.\n",
    "![conv_net.jpg](conv_net.jpg)\n",
    "上图就是卷积神经网络的基本架构, 我们用这种方式实现特征的快速提取, 并用这些特征来进行模式分类, 分类任务就交给全连接层进行.  \n",
    "### Im2col\n",
    "虽然我们上面的图是把卷积核一步一步移动, 一步一步点积并求和, 但是实际实现时我们并不会用for循环来做这件事情, 我们通常的做法是选择最能并行化的方式, 把卷积运算转为矩阵运算. 因为今天的硬件运算性能的提高已经不是以电子器件的尺度和频率取胜了, 而是以更高程度的并行化加速运算. 把卷积转为矩阵乘法的方式如下图.\n",
    "![im2col.jpg](im2col.jpg)\n",
    "$$COL = im2col(IM_i) $$\n",
    "$$IM_o = COL\\cdot FCOL+b$$\n",
    "当然执行完矩阵运算后, 这还不是结束.我们conv2d输出的是特征图, 所以我们还要有一个把矩阵重塑成NxCxHxW的特征图的reshape和permute操作.\n",
    "### conv2d的反向传播\n",
    "既然卷积可以写成矩阵乘法, 那么矩阵乘法的求导一样适用于卷积运算. 我们把卷积核展开成列向量, 与图像的col矩阵做乘法, 每个列向量的元素和卷积核中的元素有一一对应的关系, 那么我们保存卷积核时也不必用2d的形式保存, 而可以用列向量来保存. 这样只需要用矩阵乘法的求导方法计算FM和b的导数即可 $$\\frac{\\partial L}{\\partial FCOL} = COL^T \\cdot \\frac{\\partial L}{\\partial IM_o} $$\n",
    "$$\\frac{\\partial L}{\\partial b} = SUMROW\\frac{\\partial L}{\\partial IM_o} $$\n",
    "比较麻烦的是计算损失函数关于输入图像的导数, 也就是反向传播. 我们前向传播使用im2col的方法得到一张把原图像im中的元素反复使用并填充到对应位置的矩阵COL, 我们计算完矩阵COL的导数后还需要一个col2im的逆变换把它变成图像导数. 这个col2im其实就是im2col的逆操作, 原来是怎样拆分矩阵的, 现在就怎样把它拼装回去. 这个过程中会有重叠的存在, 因此处理时要格外小心. \n",
    "$$ \\frac{\\partial L}{\\partial COL} = \\frac{\\partial L}{\\partial IM_o} \\cdot FCOL^T $$\n",
    "$$ \\frac{\\partial L}{\\partial W} = col2im(\\frac{\\partial L}{\\partial COL}) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "gCFr1x_UnkTF",
    "outputId": "dfe4054f-a4fb-4c6b-a706-2ecfe0df8fca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dx:\n",
      " tensor([[[[ 0.0000e+00, -1.1921e-07,  0.0000e+00, -3.7253e-09],\n",
      "          [ 0.0000e+00,  2.3842e-07,  5.2154e-08,  5.9605e-08],\n",
      "          [-5.9605e-08,  0.0000e+00, -1.1921e-07,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  1.4901e-08,  7.4506e-08]],\n",
      "\n",
      "         [[-5.9605e-08,  0.0000e+00,  1.4901e-08,  2.9802e-08],\n",
      "          [-5.9605e-08, -1.1921e-07,  2.9802e-08,  5.9605e-08],\n",
      "          [ 5.9605e-08,  0.0000e+00,  2.3842e-07,  0.0000e+00],\n",
      "          [ 0.0000e+00,  1.1921e-07,  3.7253e-08,  2.9802e-08]],\n",
      "\n",
      "         [[-1.1921e-07,  0.0000e+00, -1.1921e-07,  5.9605e-08],\n",
      "          [ 1.1921e-07,  1.1921e-07,  0.0000e+00,  1.1921e-07],\n",
      "          [ 1.1921e-07,  2.3842e-07, -4.7684e-07, -1.1921e-07],\n",
      "          [-5.9605e-08,  0.0000e+00, -4.7684e-07,  0.0000e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 5.9605e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [-1.1921e-07,  5.9605e-08, -5.9605e-08, -1.1921e-07],\n",
      "          [ 0.0000e+00, -3.7253e-08, -1.1921e-07, -1.1176e-08],\n",
      "          [ 0.0000e+00,  2.9802e-08, -2.2352e-08,  5.9605e-08]],\n",
      "\n",
      "         [[ 5.9605e-08,  2.9802e-08,  8.9407e-08,  5.9605e-08],\n",
      "          [-5.9605e-08, -1.1921e-07, -1.1921e-07,  0.0000e+00],\n",
      "          [ 5.9605e-08, -2.9802e-08, -2.9802e-08, -5.2154e-08],\n",
      "          [ 5.9605e-08,  5.9605e-08, -1.1921e-07,  0.0000e+00]],\n",
      "\n",
      "         [[-2.2352e-08,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "          [-1.1921e-07,  1.1921e-07, -1.1921e-07,  0.0000e+00],\n",
      "          [ 0.0000e+00,  1.1921e-07,  1.1921e-07,  5.9605e-08],\n",
      "          [-5.9605e-08,  0.0000e+00,  1.1921e-07, -1.1921e-07]]]])\n",
      "dw:\n",
      " tensor([[[[ 0.0000e+00,  0.0000e+00, -7.1526e-07],\n",
      "          [ 0.0000e+00, -1.9073e-06, -9.5367e-07],\n",
      "          [ 0.0000e+00,  9.5367e-07, -9.5367e-07]],\n",
      "\n",
      "         [[ 4.7684e-07, -9.5367e-07,  0.0000e+00],\n",
      "          [-4.7684e-07, -1.9073e-06,  0.0000e+00],\n",
      "          [ 0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "\n",
      "         [[-9.5367e-07, -3.8147e-06,  1.9073e-06],\n",
      "          [ 0.0000e+00,  0.0000e+00, -1.9073e-06],\n",
      "          [ 4.7684e-07,  0.0000e+00,  1.9073e-06]]],\n",
      "\n",
      "\n",
      "        [[[-4.7684e-07, -9.5367e-07,  1.7881e-07],\n",
      "          [ 0.0000e+00, -7.1526e-07,  1.9073e-06],\n",
      "          [ 0.0000e+00,  9.5367e-07, -9.5367e-07]],\n",
      "\n",
      "         [[ 1.1921e-07, -5.6624e-07, -4.7684e-07],\n",
      "          [-9.5367e-07,  6.5565e-07,  0.0000e+00],\n",
      "          [ 4.7684e-07,  0.0000e+00, -1.1474e-06]],\n",
      "\n",
      "         [[ 0.0000e+00,  1.9073e-06,  0.0000e+00],\n",
      "          [ 0.0000e+00, -3.8147e-06,  0.0000e+00],\n",
      "          [ 9.5367e-07,  4.7684e-07, -9.5367e-07]]]])\n",
      "db:\n",
      " tensor([-4.1723e-07, -5.7220e-06])\n",
      "dx:\n",
      " tensor([[[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]],\n",
      "\n",
      "         [[0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0.]]]])\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(3,2,3,1,1)\n",
    "conv2 = Conv2d(in_channels=3, out_channels=2, kernel_size = 3,\n",
    "               stride=1, padding=1)\n",
    "conv2.weights = conv1.weight.data.numpy()\n",
    "conv2.bias = conv1.bias.data.numpy()\n",
    "\n",
    "x_train = torch.randn(2,3,4,4)\n",
    "x_train_numpy = x_train.data.numpy()\n",
    "x_train.requires_grad = True\n",
    "y_train = torch.randn(2,2,4,4)\n",
    "y_train_numpy = y_train.data.numpy()\n",
    "\n",
    "out = conv1(x_train)\n",
    "loss = F.mse_loss(out,y_train,reduction='sum')\n",
    "loss.backward()\n",
    "\n",
    "out = conv2(x_train_numpy)\n",
    "dx = conv2.backward(2*(out-y_train_numpy))\n",
    "\n",
    "print('dx:\\n',x_train.grad-torch.FloatTensor(dx))\n",
    "print('dw:\\n',conv1.weight.grad-torch.FloatTensor(conv2._dw))\n",
    "print('db:\\n',conv1.bias.grad-torch.FloatTensor(conv2._db))\n",
    "\n",
    "pool1 = nn.MaxPool2d(2,2)\n",
    "pool2 = MaxPool2d(2,2)\n",
    "\n",
    "x_train = torch.randn(2,3,4,4)\n",
    "x_train_numpy = x_train.data.numpy()\n",
    "x_train.requires_grad = True\n",
    "y_train = torch.randn(2,3,2,2)\n",
    "y_train_numpy = y_train.data.numpy()\n",
    "\n",
    "out = pool1(x_train)\n",
    "loss = F.mse_loss(out,y_train,reduction='sum')\n",
    "loss.backward()\n",
    "\n",
    "out = pool2(x_train_numpy)\n",
    "dx = pool2.backward(2*(out-y_train_numpy))\n",
    "\n",
    "print('dx:\\n',x_train.grad-torch.FloatTensor(dx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZMrjLSnDLM3o"
   },
   "source": [
    "### 任务:搭建面向CIFAR-10的CNN分类器\n",
    "使用上面写好的卷积层和池化层, 还有之前实现过的激活函数和softmax, 线性层等, 实现简单的卷积神经网络, 并用反向传播训练网络. base line是在cifar-10上达到60%的准确率. 一种最基本的模型架构为:  \n",
    "(input) - Conv1 - ReLU - Pooling - Conv2 - ReLU - Pooling - FC1 - ReLU - FC2 - (output)  \n",
    "其中卷积层使用5x5的size, Conv1的通道数为6, Conv2的通道数为16, 如果希望能让模型做得更好, 可以适当增加卷积层数和通道数, 当然相对的需要的内存和训练时间也更多. 一种VGG型的卷积网络搭建方法是, 用两层3x3的卷积核代替5x5的卷积核. 这样使用的参数更少而且层数更深, 更容易提取高级特征来让CNN学得更好. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "WEvCX7uPnzXu",
    "outputId": "6845d744-8ee7-49ce-cac2-03c77f61e7ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 6s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# load cifar-10 dataset\n",
    "(x_train_origin,t_train_origin),(x_test_origin,t_test_origin) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_img_train_normalize = x_train_origin.astype('float32') / 255.0\n",
    "x_img_test_normalize = x_test_origin.astype('float32') / 255.0\n",
    "y_img_train = t_train_origin.flatten()\n",
    "y_img_test = t_test_origin.flatten()\n",
    "\n",
    "batch_size = 100\n",
    "train_loader = DataLoader(x_img_train_normalize,y_img_train,batch_size)\n",
    "test_loader = DataLoader(x_img_test_normalize,y_img_test,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "b4WOQB5SLRFS",
    "outputId": "56ceadd9-0948-4196-a24c-c2a44063b44e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [50/500], Loss: 2.1858\n",
      "Epoch [1/10], Step [100/500], Loss: 1.7130\n",
      "Epoch [1/10], Step [150/500], Loss: 1.5685\n",
      "Epoch [1/10], Step [200/500], Loss: 1.4656\n",
      "Epoch [1/10], Step [250/500], Loss: 1.3486\n",
      "Epoch [1/10], Step [300/500], Loss: 1.2898\n",
      "Epoch [1/10], Step [350/500], Loss: 1.2907\n",
      "Epoch [1/10], Step [400/500], Loss: 1.2103\n",
      "Epoch [1/10], Step [450/500], Loss: 1.2200\n",
      "Epoch [1/10], Step [500/500], Loss: 1.1171\n",
      "Accuracy of the network on the 10000 test images: 62.23 %\n",
      "Epoch [2/10], Step [50/500], Loss: 1.0729\n",
      "Epoch [2/10], Step [100/500], Loss: 1.0632\n",
      "Epoch [2/10], Step [150/500], Loss: 1.0482\n",
      "Epoch [2/10], Step [200/500], Loss: 1.0393\n",
      "Epoch [2/10], Step [250/500], Loss: 0.9636\n",
      "Epoch [2/10], Step [300/500], Loss: 0.9367\n",
      "Epoch [2/10], Step [350/500], Loss: 0.9693\n",
      "Epoch [2/10], Step [400/500], Loss: 0.9284\n",
      "Epoch [2/10], Step [450/500], Loss: 0.9584\n",
      "Epoch [2/10], Step [500/500], Loss: 0.8768\n",
      "Accuracy of the network on the 10000 test images: 66.97 %\n",
      "Epoch [3/10], Step [50/500], Loss: 0.8611\n",
      "Epoch [3/10], Step [100/500], Loss: 0.8774\n",
      "Epoch [3/10], Step [150/500], Loss: 0.8582\n",
      "Epoch [3/10], Step [200/500], Loss: 0.8649\n",
      "Epoch [3/10], Step [250/500], Loss: 0.7939\n",
      "Epoch [3/10], Step [300/500], Loss: 0.7775\n",
      "Epoch [3/10], Step [350/500], Loss: 0.8190\n",
      "Epoch [3/10], Step [400/500], Loss: 0.7946\n",
      "Epoch [3/10], Step [450/500], Loss: 0.8077\n",
      "Epoch [3/10], Step [500/500], Loss: 0.7344\n",
      "Accuracy of the network on the 10000 test images: 69.72 %\n",
      "Epoch [4/10], Step [50/500], Loss: 0.7423\n",
      "Epoch [4/10], Step [100/500], Loss: 0.7368\n",
      "Epoch [4/10], Step [150/500], Loss: 0.7336\n",
      "Epoch [4/10], Step [200/500], Loss: 0.7679\n",
      "Epoch [4/10], Step [250/500], Loss: 0.6942\n",
      "Epoch [4/10], Step [300/500], Loss: 0.6709\n",
      "Epoch [4/10], Step [350/500], Loss: 0.7175\n",
      "Epoch [4/10], Step [400/500], Loss: 0.6914\n",
      "Epoch [4/10], Step [450/500], Loss: 0.6940\n",
      "Epoch [4/10], Step [500/500], Loss: 0.6373\n",
      "Accuracy of the network on the 10000 test images: 70.52 %\n",
      "Epoch [5/10], Step [50/500], Loss: 0.6382\n",
      "Epoch [5/10], Step [100/500], Loss: 0.6508\n",
      "Epoch [5/10], Step [150/500], Loss: 0.6459\n",
      "Epoch [5/10], Step [200/500], Loss: 0.6680\n",
      "Epoch [5/10], Step [250/500], Loss: 0.6102\n",
      "Epoch [5/10], Step [300/500], Loss: 0.5865\n",
      "Epoch [5/10], Step [350/500], Loss: 0.6425\n",
      "Epoch [5/10], Step [400/500], Loss: 0.6334\n",
      "Epoch [5/10], Step [450/500], Loss: 0.6005\n",
      "Epoch [5/10], Step [500/500], Loss: 0.5630\n",
      "Accuracy of the network on the 10000 test images: 71.55 %\n",
      "Epoch [6/10], Step [50/500], Loss: 0.5693\n",
      "Epoch [6/10], Step [100/500], Loss: 0.5745\n",
      "Epoch [6/10], Step [150/500], Loss: 0.5730\n",
      "Epoch [6/10], Step [200/500], Loss: 0.5774\n",
      "Epoch [6/10], Step [250/500], Loss: 0.5382\n",
      "Epoch [6/10], Step [300/500], Loss: 0.5255\n",
      "Epoch [6/10], Step [350/500], Loss: 0.5694\n",
      "Epoch [6/10], Step [400/500], Loss: 0.5812\n",
      "Epoch [6/10], Step [450/500], Loss: 0.5419\n",
      "Epoch [6/10], Step [500/500], Loss: 0.5027\n",
      "Accuracy of the network on the 10000 test images: 70.42 %\n",
      "Epoch [7/10], Step [50/500], Loss: 0.5116\n",
      "Epoch [7/10], Step [100/500], Loss: 0.5005\n",
      "Epoch [7/10], Step [150/500], Loss: 0.5107\n",
      "Epoch [7/10], Step [200/500], Loss: 0.5065\n",
      "Epoch [7/10], Step [250/500], Loss: 0.4907\n",
      "Epoch [7/10], Step [300/500], Loss: 0.4651\n",
      "Epoch [7/10], Step [350/500], Loss: 0.5190\n",
      "Epoch [7/10], Step [400/500], Loss: 0.5193\n",
      "Epoch [7/10], Step [450/500], Loss: 0.4914\n",
      "Epoch [7/10], Step [500/500], Loss: 0.4424\n",
      "Accuracy of the network on the 10000 test images: 71.23 %\n",
      "Epoch [8/10], Step [50/500], Loss: 0.4496\n",
      "Epoch [8/10], Step [100/500], Loss: 0.4479\n",
      "Epoch [8/10], Step [150/500], Loss: 0.4624\n",
      "Epoch [8/10], Step [200/500], Loss: 0.4610\n",
      "Epoch [8/10], Step [250/500], Loss: 0.4538\n",
      "Epoch [8/10], Step [300/500], Loss: 0.4083\n",
      "Epoch [8/10], Step [350/500], Loss: 0.4698\n",
      "Epoch [8/10], Step [400/500], Loss: 0.4345\n",
      "Epoch [8/10], Step [450/500], Loss: 0.4315\n",
      "Epoch [8/10], Step [500/500], Loss: 0.3947\n",
      "Accuracy of the network on the 10000 test images: 71.73 %\n",
      "Epoch [9/10], Step [50/500], Loss: 0.3685\n",
      "Epoch [9/10], Step [100/500], Loss: 0.4016\n",
      "Epoch [9/10], Step [150/500], Loss: 0.3872\n",
      "Epoch [9/10], Step [200/500], Loss: 0.3999\n",
      "Epoch [9/10], Step [250/500], Loss: 0.3940\n",
      "Epoch [9/10], Step [300/500], Loss: 0.3658\n",
      "Epoch [9/10], Step [350/500], Loss: 0.4064\n",
      "Epoch [9/10], Step [400/500], Loss: 0.3446\n",
      "Epoch [9/10], Step [450/500], Loss: 0.3472\n",
      "Epoch [9/10], Step [500/500], Loss: 0.3464\n",
      "Accuracy of the network on the 10000 test images: 71.42 %\n",
      "Epoch [10/10], Step [50/500], Loss: 0.3095\n",
      "Epoch [10/10], Step [100/500], Loss: 0.3632\n",
      "Epoch [10/10], Step [150/500], Loss: 0.3677\n",
      "Epoch [10/10], Step [200/500], Loss: 0.3709\n",
      "Epoch [10/10], Step [250/500], Loss: 0.3659\n",
      "Epoch [10/10], Step [300/500], Loss: 0.3278\n",
      "Epoch [10/10], Step [350/500], Loss: 0.3516\n",
      "Epoch [10/10], Step [400/500], Loss: 0.3118\n",
      "Epoch [10/10], Step [450/500], Loss: 0.3226\n",
      "Epoch [10/10], Step [500/500], Loss: 0.3673\n",
      "Accuracy of the network on the 10000 test images: 69.47 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Train loss(Cross Entropy)')"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "total_step = len(train_loader)\n",
    "\n",
    "# 简单的三层卷积神经网络\n",
    "# [conv->relu]->pool x 3 -> fc -> relu -> fc -> softmax\n",
    "model = Sequential(\n",
    "    Conv2d(in_channels=3, out_channels=32, kernel_size = 3,\n",
    "           stride=1,padding=1),\n",
    "    ReLU(),\n",
    "    MaxPool2d(kernel_size=2,stride=2),\n",
    "    Conv2d(in_channels=32, out_channels=64, kernel_size = 3,\n",
    "           stride=1,padding=1),\n",
    "    ReLU(),\n",
    "    MaxPool2d(kernel_size=2,stride=2),\n",
    "    Conv2d(in_channels=64, out_channels=128, kernel_size = 3,\n",
    "           stride=1,padding=1),\n",
    "    ReLU(),\n",
    "    MaxPool2d(kernel_size=2,stride=2),\n",
    "    Flatten(),\n",
    "    Linear(128*4*4,128),\n",
    "    ReLU(),\n",
    "    Linear(128,10),\n",
    ")\n",
    "loss_func = CrossEntropyLossWithSoftMax(10)\n",
    "optimizer = Adam(0.001)\n",
    "model.apply_optim(optimizer)\n",
    "\n",
    "loss_list = []\n",
    "log_step = 50\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.\n",
    "    for i in range(total_step):\n",
    "        x,y = train_loader.get_batch()\n",
    "        x = x.transpose(0,3,1,2)\n",
    "        # Forward pass\n",
    "        logits = model(x)\n",
    "        # calculate loss\n",
    "        loss,dlo\n",
    "        gits = loss_func(logits,y)\n",
    "        # Backward\n",
    "        model.zero_grad()\n",
    "        model.backward(dlogits)\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % log_step == 0:\n",
    "            running_loss/=log_step\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, running_loss))\n",
    "            loss_list.append(running_loss)\n",
    "            running_loss = 0.\n",
    "            \n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for i in range(len(test_loader)):\n",
    "        x,y = test_loader.get_batch()\n",
    "        x = x.transpose(0,3,1,2)\n",
    "        logits = model(x)\n",
    "        predicted = np.argmax(logits, axis = 1)\n",
    "        total += y.shape[0]\n",
    "        correct += (predicted == y).sum()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %.2f %%'%(100 * correct / total))\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.title('Train loss(Cross Entropy)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eDD6gAH4oBsT"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "Cifar.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
