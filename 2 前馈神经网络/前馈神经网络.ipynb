{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 前馈神经网络\n",
    "把多个仿射层级联起来, 形成神经网络\n",
    "![FFNN.jpg](FFNN.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T05:25:23.261010Z",
     "start_time": "2020-08-11T05:25:22.990706Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "path = os.getcwd()\n",
    "os.chdir('..')\n",
    "from deepnotes import *\n",
    "os.chdir(path)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adam\n",
    "SGD优化器比较简单高效，而Adam优化器在非凸优化中的表现比较良好。它使用两个动量因子实现一阶点估计和二阶矩估计，使用矩估计的开方作为分母来实现自适应学习率，是一种结合了momentum方法和RMSProp两种优化器优点的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 激活函数\n",
    "只有线性层的网络, 其本质就是多个矩阵相乘, 化简后得到的仍然是矩阵, 无法得到非线性. 为了让网络有非线性的能力, 我们会在线性层之前穿插激活函数.也就是整个神经网络的输出写做\n",
    "$$ o = (...acti((acti(xW_1+b_1))W_2+b_2)...)W_n+b_n $$\n",
    "激活函数接收m维向量, 在向量的每个元素上做非线性变换. 输出m维向量. 逻辑回归时我们用到了sigmoid这种函数, 它可以作为一种激活函数, 但它不是最好的函数. sigmoid虽然求导简单但是存在一些问题, 因为它的前向传播和反向传播计算导数的公式是\n",
    "$$ f(v)=\\frac {1} {1+e^{(-v)}}$$\n",
    "$$ f^{'}(v)=f(v)(1-f(v)) $$\n",
    "可以看见, 部分导是恒小于1的. 如果用这种激活函数就会在较为深层的网络(比如ResNet会有十几层的卷积层和线性层)中出现梯度的快速衰减, 以至于上层的线性层参数得不到有效更新, 进而无法有效训练网络. 在ResNet中我们会用一些技巧防止这个现象出现, 其中包括使用特殊的激活函数ReLU, 线性整流函数. \n",
    "$$ ReLU(v) = v\\ if\\ v>0\\ else\\ 0 $$ \n",
    "$$ ReLU'(v) = 1\\ if\\ v>0\\ else\\ 0 $$ \n",
    "在RNN中, 我们会用tanh这个函数代替sigmoid, 从而让梯度不衰减得太厉害.  \n",
    "$$ tanh(v) = \\frac{e^x-e^{-x}}{e^x+e^{-x}} $$\n",
    "$$ tanh'(v) = 1-(tanh(v))^2 $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T05:25:46.618551Z",
     "start_time": "2020-08-11T05:25:44.071284Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# load mnist dataset\n",
    "(x_train_origin,t_train_origin),(x_test_origin,t_test_origin) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# batch data loader\n",
    "X_train,X_test = x_train_origin/255.,x_test_origin/255.\n",
    "batch_size = 100\n",
    "\n",
    "train_loader = DataLoader(X_train,t_train_origin,batch_size)\n",
    "test_loader = DataLoader(X_test,t_test_origin,batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T05:27:16.231090Z",
     "start_time": "2020-08-11T05:26:29.019998Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/600], Loss: 0.5787\n",
      "Epoch [1/5], Step [200/600], Loss: 0.2822\n",
      "Epoch [1/5], Step [300/600], Loss: 0.2136\n",
      "Epoch [1/5], Step [400/600], Loss: 0.1944\n",
      "Epoch [1/5], Step [500/600], Loss: 0.1840\n",
      "Epoch [1/5], Step [600/600], Loss: 0.1331\n",
      "Epoch [2/5], Step [100/600], Loss: 0.1221\n",
      "Epoch [2/5], Step [200/600], Loss: 0.1138\n",
      "Epoch [2/5], Step [300/600], Loss: 0.1027\n",
      "Epoch [2/5], Step [400/600], Loss: 0.1000\n",
      "Epoch [2/5], Step [500/600], Loss: 0.1043\n",
      "Epoch [2/5], Step [600/600], Loss: 0.0753\n",
      "Epoch [3/5], Step [100/600], Loss: 0.0731\n",
      "Epoch [3/5], Step [200/600], Loss: 0.0690\n",
      "Epoch [3/5], Step [300/600], Loss: 0.0646\n",
      "Epoch [3/5], Step [400/600], Loss: 0.0608\n",
      "Epoch [3/5], Step [500/600], Loss: 0.0649\n",
      "Epoch [3/5], Step [600/600], Loss: 0.0459\n",
      "Epoch [4/5], Step [100/600], Loss: 0.0450\n",
      "Epoch [4/5], Step [200/600], Loss: 0.0439\n",
      "Epoch [4/5], Step [300/600], Loss: 0.0416\n",
      "Epoch [4/5], Step [400/600], Loss: 0.0410\n",
      "Epoch [4/5], Step [500/600], Loss: 0.0460\n",
      "Epoch [4/5], Step [600/600], Loss: 0.0335\n",
      "Epoch [5/5], Step [100/600], Loss: 0.0318\n",
      "Epoch [5/5], Step [200/600], Loss: 0.0283\n",
      "Epoch [5/5], Step [300/600], Loss: 0.0278\n",
      "Epoch [5/5], Step [400/600], Loss: 0.0276\n",
      "Epoch [5/5], Step [500/600], Loss: 0.0283\n",
      "Epoch [5/5], Step [600/600], Loss: 0.0259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'Train loss(Cross Entropy)')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x20a4cec13c8>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "total_step = len(train_loader)\n",
    "\n",
    "model = Sequential(\n",
    "    Linear(28*28,256),\n",
    "    ReLU(),\n",
    "    Linear(256,128),\n",
    "    ReLU(),\n",
    "    Linear(128,10)\n",
    ")\n",
    "loss_func = CrossEntropyLossWithSoftMax(10)\n",
    "optimizer = Adam(0.001)\n",
    "model.apply_optim(optimizer)\n",
    "\n",
    "loss_list = []\n",
    "log_step = 100 \n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.\n",
    "    for i in range(total_step):\n",
    "        x,y = train_loader.get_batch()\n",
    "        x = x.reshape(x.shape[0],-1)\n",
    "        # Forward pass\n",
    "        logits = model(x)\n",
    "        # calculate loss\n",
    "        loss,dlogits = loss_func(logits,y)\n",
    "        # Backward\n",
    "        model.zero_grad()\n",
    "        model.backward(dlogits)\n",
    "        # optimize\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if (i+1) % log_step == 0:\n",
    "            running_loss/=log_step\n",
    "            print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                   .format(epoch+1, num_epochs, i+1, total_step, running_loss))\n",
    "            loss_list.append(running_loss)\n",
    "            running_loss = 0.\n",
    "\n",
    "plt.plot(loss_list)\n",
    "plt.title('Train loss(Cross Entropy)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-08-11T05:27:31.527674Z",
     "start_time": "2020-08-11T05:27:31.409843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 96.25 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "for i in range(len(test_loader)):\n",
    "    x,y = test_loader.get_batch()\n",
    "    x = x.reshape(x.shape[0],-1)\n",
    "    outputs = model(x)\n",
    "    predicted = np.argmax(outputs, axis = 1)\n",
    "    total += y.shape[0]\n",
    "    correct += (predicted == y).sum()\n",
    "    \n",
    "print('Accuracy of the network on the 10000 test images: %.2f %%'%(100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络优化遇到的问题\n",
    "**局部最优**  \n",
    "我们一直避而不谈的一个问题是，为什么神经网络能用SGD train到全局最优？前面学习逻辑回归时，梯度下降能把loss优化到最优，是因为不论是MSE误差，还是BCE误差，它们在逻辑回归的模型上都是凸优化，所以我们必然能用梯度下降找到最优解。但神经网络不同，我们并不知道它是不是凸优化啊？  \n",
    "事实上也和我们的直觉相同，神经网络不是凸优化，而且我们也很难去找到一个全局最优。一个相当反直觉的现实是，我们连局部最优都很难找到。优化理论告诉我们，一个函数上的某点如果是局部最优，那么它的Hessian矩阵是正定的。正定的矩阵要求所有矩阵特征值都是正的，而在一个大型网络里，对成千上万的参数所在的高维空间，计算出的H矩阵将会非常巨大，特征值也非常多。而想找到一个点让所有特征值都是正的极为困难，也就是，在参数空间内，我们几乎不可能触摸到局部最优，这也就让所谓被\"局部最优\"卡住，找不到全局最优的事情几乎不可能发生。  \n",
    "**鞍点**   \n",
    "换句话来说，我们训练神经网络时面对的问题并不是被局部最优限制，而是被一般的0梯度点，即鞍点限制。而幸运的是，鞍点并不具备局部最小点的那种强大的吸引力，在随机梯度下降和随机初始化下生成的网络，虽然会经过鞍点，但在连续的梯度下降优化下，都会跳出鞍点。而牛顿法之所以无法在神经网络优化中取得比较好的效果，就是因为它会落入鞍点。  \n",
    "**高原**  \n",
    "还有一些在使用sigmoid和tanh时我们不会遇到的问题，如果我们使用relu作为激活函数，则loss的空间很有可能出现大片的，平坦的区域。在这些区域上梯度完全为0，优化无法继续进行。一种解决方案是使用leaky relu，使用更好的参数初始化策略，和更好的梯度学习算法。  \n",
    "**梯度爆炸与消失**  \n",
    "在深层的计算图中，梯度很可能随着反向传播衰减，以至于梯度很快为接近于0.这一点在深度的卷积网络和RNN中经常出现，CNN解决这个问题的方法是把上层的神经元直接和几层后的神经元连接，允许梯度跨层传播，抑制梯度的消失。RNN中因为计算图要随着序列长度变化，梯度还很容易变得陡峭，RNN解决这个问题的方法是使用更柔和的LSTM。  \n",
    "**我们想要的**  \n",
    "回顾一下我们上面做的事情，我们想要的不是神经网络能完美拟合训练集，而是具有最好的泛化能力。所以我们才用了那么多的方法防止过拟合，这也说明了，找不到一个全局最优其实一点都不重要，全局最优一般对应着较差的泛化能力，我们真正的训练，很多时候都是\"什么都没有做到\"就停止训练了，但这并不重要。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
