{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 泰勒展开\n",
    "$$ f(x) \\approx f(x_0)+g(x_0)^T(x-x_0)+\\frac{1}{2}(x-x_0)^TH(x_0)(x-x_0) $$\n",
    "函数f接受一个向量,返回一个实数.我们对实数求导,会得到一个和x相同维度的梯度向量g.对g的每项关于求导会得到二阶导数的矩阵Hessian矩阵H.它们组成上面的代数形式的函数泰勒展开式.泰勒展开用二次型函数在$x_0$处近似f函数."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 梯度下降\n",
    "无约束优化问题的目的是找到一个目标函数f的最小极值点,如果我们使用一阶近似,上面的函数写成\n",
    "$$ f(x) = f(x_0)+g(x_0)^T(x-x_0) $$\n",
    "$$ \\nabla f = g(x_0) $$\n",
    "这是一个线性函数,只要沿着梯度方向走下去就能让函数值不断减小.而目标函数在$x_0$附近和线性函数的性质相似,也是只要沿着梯度方向走一小步就能让函数值减小.为此我们有固定步长的梯度下降法\n",
    "$$ x \\leftarrow x-\\alpha\\nabla f$$\n",
    "梯度下降法适用性很广泛,在大多数优化问题中,梯度下降都能在有限次迭代后找到局部最优解."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 牛顿法\n",
    "如果我们能计算目标函数的Hessian矩阵,就能用二阶近似逼近函数.二次型函数有一个极值点,而且我们有一个结论是:只要在$x_0$处H矩阵正定,则这个极值点是一个极小点.因此,在优化问题中,我们经常使用这种方法,通过不断在当前迭代点进行二阶泰勒展开并计算这个二次型的极值点,然后把x更新为这个点,迭代直到当前梯度为0.  \n",
    "我们计算上面的二次型函数的梯度,让它等于0来计算二次型的极值点\n",
    "$$ \\nabla f = g(x_0)+H(x-x_0) = 0 $$\n",
    "$$ x \\leftarrow x_0-H^{-1}g $$\n",
    "这样迭代多次就能找到一个0梯度点,但牛顿法存在一些问题,就是强烈要求矩阵正定.如果矩阵非正定就不能保证迭代过程中函数值是下降的,因此牛顿法在凸优化问题里表现良好,而在非凸优化问题里甚至不能保证找到一个局部最优解(比如神经网络优化),它经常会让迭代在一个鞍点停止."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KKT条件\n",
    "在有约束的优化问题中,我们一般会通过构造拉格朗日函数来把问题转变成无约束优化.约束优化问题\n",
    "$$ minimize\\quad f(x) $$\n",
    "$$ s.t.\\quad g(x)=0 \\quad h(x)\\le 0 $$\n",
    "KKT条件是约束优化问题极值点满足的必要条件\n",
    "$$ \\frac{\\partial L} {\\partial x} = \\frac{\\partial f} {\\partial x}+\\lambda \\frac{\\partial g} {\\partial x}+\\mu \\frac{\\partial h} {\\partial x} = 0 $$\n",
    "$$ \\mu\\cdot h(x) = 0 $$\n",
    "$$ \\mu \\ge 0 $$\n",
    "$$ g(x)=0 \\quad h(x)\\le 0 $$\n",
    "这里不给出代数证明,只从直观上理解.对等式约束,因为所有的函数都在函数g(x)描述的曲面上,所以极值点处目标函数的等高线和g曲面一定相切.即$\\nabla g(x)$和$\\nabla f(x)$共线,这也就是不存在不等式约束项h时,上面等式1的$\\frac{\\partial f} {\\partial x}+\\lambda \\frac{\\partial g} {\\partial x} = 0$的由来.  \n",
    "如果是不等式约束,我们可以分情况讨论.不等式会给出一个x的可行域,当无约束时的极值点在可行域以内时,这个约束实际上并不发挥作用;而当无约束时的极值点在可行域以外时,极值点一定会在函数h(x)所描述的曲面上,也就是它退化为等式约束条件,满足h(x) = 0.这也就是上面的$ \\mu\\cdot h(x) = 0 $一项,当$\\mu = 0$时,h(x)可以任意取值,且上面的等式1也变为$\\frac{\\partial f} {\\partial x}+\\lambda \\frac{\\partial g} {\\partial x} = 0$,即约束不发挥作用.当$\\mu \\ne 0$时,$h(x) = 0$,问题是等式约束.  \n",
    "至于$\\mu \\ge 0$这一项,事实上我们可以从下面的图上看到,因为如果$\\mu \\lt 0$,即上面的条件允许$\\nabla h(x_0)$和$\\nabla f(x_0)$方向相同,我们知道负梯度方向能让目标函数值下降.则只需要沿着这个负梯度方向移动一个很小的步长,我们就能得到一个不同于$x_0$的点$x_1$,而这个点的目标函数值$f(x_1)\\lt f(x_0)$,h的函数值$h(x_1)\\lt f(h_0) = 0$.这样$x_1$仍然满足不等式约束,但是却得到了更小的函数值,这就让$\\mu \\lt 0$成立时,x一定不是极值点.  \n",
    "但是$\\mu \\gt 0$时,f与h的梯度方向相反,$h(x_1)\\gt f(h_0) = 0$,不满足约束条件.即这一点有可能是极值点.\n",
    "![Inequality_constraint_diagram.png](pics/Inequality_constraint_diagram.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
